{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  install speechbrain using conda\n",
    "# %pip install speechbrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/0B6391AD-84E2-41E4-97C6-78C0DA3D0D56: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/E2CBE38F-6941-45F8-AE2C-E926D2132B9A: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/5659D651-715A-4272-9483-51FED1F1C59C: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/BAC652B2-BDC9-4BC6-AE4A-C5DF27D2B290: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/8DD719ED-7FF4-4B5C-8604-0BCDE928BA0F: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/A44A690E-B8B1-44F9-AEA8-D5FB6FDADB82: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/3C0B19F4-1338-49A8-8580-790CD9404333: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/AAA88776-7839-4CB2-B6DE-7E47B4D9DD67: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/26C437B3-7947-4CF8-B06C-1EBCD80CE3FB: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/2BCD94E3-8A38-49BA-AEAB-35ACD527B3A1: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/6D299625-43AA-4545-9A2D-431053498944: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/2FEBBCF0-E797-4545-965C-6874727D2188: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/3F87BFF1-DCF4-4F24-9B30-DFA2636629A0: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/C2D1E578-182A-47FD-9C01-F8DA2547D082: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/6ED05064-FBF0-4EBD-809E-852C81B7AF64: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/0A4D650E-B418-4428-AED9-F2418233FACA: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/CF9EBEF1-53B1-433B-99A7-546EB13D9151: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/E3EF617B-8C2A-4E09-B746-AA0BEFCE3484: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/6BD469FD-05CA-46D4-80C8-105E609F3D0C: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/BF1E80BC-4540-4798-8D77-754AC3EBF928: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/B22F546C-65CD-446D-A04B-F7BC27D9EFF1: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/604FD267-7EFD-4197-AC37-FF984F439F13: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/04507303-A628-41F8-A2FE-2E9E9CA6C629: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/DAA4FA5D-D70A-42AD-9A96-8B412070A95B: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/1346A7DD-F8D1-4537-9553-966AC4265129: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/D3DC50AA-91E0-46CE-A8F9-4A138400496E: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/33EE750F-7165-4C36-A386-7873BAAE9206: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/2EB5FCD9-7BD3-4913-904B-A31AAD7E634D: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/99F96444-C693-499B-BC8D-5D37AEEE0B76: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/8D2B077E-88B5-4995-BDE1-8AC1B59A67BB: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/41B3E0B6-DF93-48A5-A85B-4AB64C208E84: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/5BDDB807-B904-4469-A75B-7932D40A77BE: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/89D24B11-7579-417F-AF77-22B2F4D697BB: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/07AABDEC-85BF-410F-A95F-2C255631BD8A: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/337F1678-37C5-459A-86C5-464F5FCD3A2F: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/F846E38D-CA0C-4FE0-ADF2-BBDC9E83FF2B: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/27C58AFE-C663-4856-85FA-49365D3A9868: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/F7940414-8184-430D-8F72-8379F77710A6: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/38246265-EED4-413A-862A-BF3FA062D783: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/32E3C42F-15FA-47C2-9692-97E3B059D630: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/9641E3BC-87AE-4434-959F-FB564713E807: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/A5A2C5B4-063A-4F00-BD80-C403D1D99110: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/DE602094-839E-4EB5-AEF9-3119C27D2E52: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/D4F8F26E-17D9-4C05-BBB6-CA5D72E7DE9E: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/1CE40F52-E024-48E5-8720-3BFBECC8C3DD: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/013DADFE-6D51-49B4-B8E4-691F6B4A60B7: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/EF701090-882B-4A69-9619-47EB446F512F: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/D92D0AA0-8797-4532-A1C8-DFBC42AC3792: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/388D217A-F8DE-4812-9D63-DC273C1D5614: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/502F818D-A83C-4ABE-A728-873B214EE900: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/076ACD98-C11C-4441-A9F3-91AFE0C23C16: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/3215DEAF-DA09-41FD-A4C7-110B560AD8F1: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/F25F93CE-1B89-4F6F-A98E-7BE371FD613C: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/A4A249D0-EA30-459D-9ACE-55B9EBDB828F: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/67B39E65-5F22-403C-80F4-0BCF2864A273: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/832987C3-DCAF-4AD2-A60B-7CC9DC5EAB95: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/89ECCE63-A6FF-484E-ABE3-1ACF9A2FA2D5: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/B71FEBD3-EBD3-4D08-874C-69F27938B390: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/C83031AA-FB09-4A23-9B8B-3F10011F309C: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/EB50EA86-7346-4398-AC04-9C6247E817F0: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/B9E10A78-7963-4612-8FE9-56C1C45E4B00: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/EA09565C-F6EE-44D3-931B-E37D6D1C60CD: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/0B7C92DB-FE65-49DE-9C5B-E970F191067D: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/0060E2D6-6237-4B37-95FB-975191B5F374: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/EB359BCF-F24A-4CC1-A49E-F93FF08FD677: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/26F89DE3-7C7B-4BE9-9C73-15F09D97DF04: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/880738FB-5D9B-48B6-B88A-BB865534E3AD: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/DE8AD23B-47AA-4907-9715-AF53D06351B4: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/F8D82546-1070-4E1C-B2C4-37A4B604FBBA: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/54F71613-B6EC-4B5E-8820-A4C324E284AA: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/EFB099A3-9D1B-4B78-93DD-1FA65271709D: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/6D2DF3F5-9C91-46DF-879A-6D8EBE8BF815: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/A3C9E9D4-005A-4A8D-B27B-7C176C9D5117: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/039F4E3F-3F11-4842-87C8-CC0F540BB815: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/CD6CDEFC-44CE-4EF0-B59E-D1BA46E56365: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/F956B372-DA8A-4011-8639-E6279AF8E870: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/BD8D3932-7502-434C-9264-F832CEA0DD1F: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/C32464ED-DDCF-498A-B518-6E423C47D12E: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/018FAE92-64A3-44D4-A13D-B9C5E015CCFF: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/8E6FDBAA-CB9D-44B8-96A5-62040FB36292: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/1F85421D-E742-466A-8B12-CF12F9A482E8: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/0F18B193-B7A9-450C-91CA-48C3F55420CE: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/F6906DEA-9C73-4973-A0F0-42142A5CDAFD: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/5AB838E6-FC96-43E4-8EF2-350E9C481F71: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/2D70BFBF-F778-42B0-B8CD-5CA8B1697271: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/F480C8E4-8633-4833-ADDD-5EEAEC238CE6: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/6A98B1F3-B4E7-4753-B23B-1056245143B9: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/C01C97CF-4D0A-44F1-AE5F-4D78E7D2D3A6: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/53792F29-B7E2-45B6-AD23-055EF5488347: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/4A868147-A652-4D23-96B2-D77F07C80C3F: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/100E47BC-C2DF-4225-9734-FCA056F1AE26: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/DF73A0E6-AEFB-48CA-9F2A-CE6F4B94429C: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/135C7D62-2B20-45AF-8FC9-331BDB58DF95: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/7641D488-D115-40D8-8AFF-B4BC95A2359C: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/6C87C474-38A0-4D29-8406-3B7A341D1266: Permission denied\n",
      "cp: ./recordings/.CloudRecordings_SUPPORT/_FBF/F9C6418D-222B-4E1D-B22F-AF8188396403: Permission denied\n"
     ]
    }
   ],
   "source": [
    "# copy all macos recordings to the current directory/recordings from Library/Application\\ Support/com.apple.voicememos/Recordings\n",
    "%cp -r ~/Library/Application\\ Support/com.apple.voicememos/Recordings/ ./recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all m4a files to wav files\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_m4a_to_wav(m4a_path, wav_path):\n",
    "    audio = AudioSegment.from_file(m4a_path, format='m4a')\n",
    "    audio.export(wav_path, format='wav')\n",
    "\n",
    "# Use this function in your loop\n",
    "for file in os.listdir(\"./recordings\"):\n",
    "    if file.endswith(\".m4a\") and not os.path.exists(\"./recordings/\" + os.path.splitext(file)[0] + '.wav'):\n",
    "        m4a_path = \"./recordings/\" + file\n",
    "        wav_path = \"./recordings/\" + os.path.splitext(file)[0] + '.wav'  # replace .m4a with .wav\n",
    "        convert_m4a_to_wav(m4a_path, wav_path)\n",
    "        print(\"Converted\", m4a_path, \"to\", wav_path)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ASR model\n",
    "from speechbrain.pretrained import EncoderDecoderASR\n",
    "\n",
    "asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-crdnn-rnnlm-librispeech\", savedir=\"pretrained_models/asr-crdnn-rnnlm-librispeech\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skippig: 20211029 023911-5D86DF0E.wav\n",
      "File already exists, skippig: 20200310 142510-45F4ABA3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/SpectralOps.cpp:867.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39m\"\u001b[39m\u001b[39m./transcriptions/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(file)[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      7\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m./transcriptions/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(file)[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m     transcription \u001b[39m=\u001b[39m asr_model\u001b[39m.\u001b[39;49mtranscribe_file(\u001b[39m\"\u001b[39;49m\u001b[39m./recordings/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m file)\n\u001b[1;32m      9\u001b[0m     \u001b[39m# print file name and transcription to console with process indicator\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTranscribing: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m file)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/speechbrain/pretrained/interfaces.py:573\u001b[0m, in \u001b[0;36mEncoderDecoderASR.transcribe_file\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    571\u001b[0m batch \u001b[39m=\u001b[39m waveform\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m    572\u001b[0m rel_length \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1.0\u001b[39m])\n\u001b[0;32m--> 573\u001b[0m predicted_words, predicted_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtranscribe_batch(\n\u001b[1;32m    574\u001b[0m     batch, rel_length\n\u001b[1;32m    575\u001b[0m )\n\u001b[1;32m    576\u001b[0m \u001b[39mreturn\u001b[39;00m predicted_words[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/speechbrain/pretrained/interfaces.py:635\u001b[0m, in \u001b[0;36mEncoderDecoderASR.transcribe_batch\u001b[0;34m(self, wavs, wav_lens)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    634\u001b[0m     wav_lens \u001b[39m=\u001b[39m wav_lens\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 635\u001b[0m     encoder_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_batch(wavs, wav_lens)\n\u001b[1;32m    636\u001b[0m     predicted_tokens, scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmods\u001b[39m.\u001b[39mdecoder(encoder_out, wav_lens)\n\u001b[1;32m    637\u001b[0m     predicted_words \u001b[39m=\u001b[39m [\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mdecode_ids(token_seq)\n\u001b[1;32m    639\u001b[0m         \u001b[39mfor\u001b[39;00m token_seq \u001b[39min\u001b[39;00m predicted_tokens\n\u001b[1;32m    640\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/speechbrain/pretrained/interfaces.py:604\u001b[0m, in \u001b[0;36mEncoderDecoderASR.encode_batch\u001b[0;34m(self, wavs, wav_lens)\u001b[0m\n\u001b[1;32m    602\u001b[0m wavs \u001b[39m=\u001b[39m wavs\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m    603\u001b[0m wavs, wav_lens \u001b[39m=\u001b[39m wavs\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice), wav_lens\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 604\u001b[0m encoder_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmods\u001b[39m.\u001b[39;49mencoder(wavs, wav_lens)\n\u001b[1;32m    605\u001b[0m \u001b[39mreturn\u001b[39;00m encoder_out\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/speechbrain/nnet/containers.py:191\u001b[0m, in \u001b[0;36mLengthsCapableSequential.forward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m    189\u001b[0m     x \u001b[39m=\u001b[39m layer(x, lengths\u001b[39m=\u001b[39mlengths)\n\u001b[1;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    193\u001b[0m     x \u001b[39m=\u001b[39m x[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/speechbrain/nnet/containers.py:144\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Applies layers in sequence, passing only the first element of tuples.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \n\u001b[1;32m    138\u001b[0m \u001b[39mArguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39m    The input tensor to run through the network.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m--> 144\u001b[0m     x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m    145\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    146\u001b[0m         x \u001b[39m=\u001b[39m x[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/speechbrain/nnet/containers.py:144\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Applies layers in sequence, passing only the first element of tuples.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \n\u001b[1;32m    138\u001b[0m \u001b[39mArguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39m    The input tensor to run through the network.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m--> 144\u001b[0m     x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m    145\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    146\u001b[0m         x \u001b[39m=\u001b[39m x[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/speechbrain/nnet/containers.py:144\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Applies layers in sequence, passing only the first element of tuples.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \n\u001b[1;32m    138\u001b[0m \u001b[39mArguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39m    The input tensor to run through the network.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m--> 144\u001b[0m     x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m    145\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    146\u001b[0m         x \u001b[39m=\u001b[39m x[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/speechbrain/nnet/CNN.py:652\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    647\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    648\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPadding must be \u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcausal\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    649\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding\n\u001b[1;32m    650\u001b[0m     )\n\u001b[0;32m--> 652\u001b[0m wx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munsqueeze:\n\u001b[1;32m    655\u001b[0m     wx \u001b[39m=\u001b[39m wx\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/echolingo/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# transcribe all recordings and save to a file\n",
    "import os\n",
    "\n",
    "# Get a list of all .wav files in the directory\n",
    "wav_files = [file for file in os.listdir(\"./recordings\") if file.endswith(\".wav\")]\n",
    "\n",
    "# Get file sizes and sort files by size\n",
    "wav_files.sort(key=lambda file: os.path.getsize(\"./recordings/\" + file))\n",
    "\n",
    "for file in wav_files:\n",
    "    # If file does not exist, create it\n",
    "    if not os.path.exists(\"./transcriptions/\" + os.path.splitext(file)[0] + '.txt'):\n",
    "        f = open(\"./transcriptions/\" + os.path.splitext(file)[0] + '.txt', \"w\")\n",
    "        transcription = asr_model.transcribe_file(\"./recordings/\" + file)\n",
    "        # Print file name and transcription to console with process indicator\n",
    "        print(\"Transcribing: \" + file)\n",
    "        # Open file which is file without extension + .txt\n",
    "        f.write(file + \": \" + transcription + \"\\n\")\n",
    "        print(file + \": \" + transcription)\n",
    "        f.close()\n",
    "        # Delete the wav file since we don't need it anymore and wav files are large\n",
    "        os.remove(\"./recordings/\" + file)\n",
    "    else:\n",
    "        print(\"File already exists, skipping: \" + file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echolingo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
